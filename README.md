# ðŸ§  Artificial Neural Network (ANN) Projects

Welcome to the **ANN (Artificial Neural Network)** repository!  
This repository contains various beginner-to-intermediate level ANN-based projects implemented using **Python and NumPy**, showcasing how neural networks can be applied to solve real-world problems using basic logic, perceptrons, and activation functions.

---

## ðŸ“‚ Contents

Each folder or script contains:
- Problem Statement
- Dataset (Randomly generated or custom logic)
- Training using **Gradient Descent / Perceptron Learning Rule**
- Prediction for new input
- Use of **Activation Functions**: `Step`, `Sigmoid`, `ReLU`, and `Tanh`

---

## ðŸ§  Concepts Covered

- Perceptron Learning Algorithm  
- Step Activation Function  
- Gradient Descent Optimization  
- Input Feature Normalization (Z-score scaling)  
- Prediction on New Inputs  
- Use of `Sigmoid`, `ReLU`, `Tanh` for analysis
  
---

## ðŸ”¢ Activation Functions

| Function | Formula | Output Range |
|---------|---------|----------------|
| Step     | 1 if x â‰¥ 0 else 0 | 0 or 1 |
| Sigmoid  | 1 / (1 + e^(-x))  | (0, 1) |
| ReLU     | max(0, x)         | [0, âˆž) |
| Tanh     | (e^x - e^-x)/(e^x + e^-x) | (-1, 1) |

---

## ðŸš€ How to Run

1. Clone the repository:
   ```bash
   git clone https://github.com/your-username/ANN-Projects.git
   cd ANN-Projects

